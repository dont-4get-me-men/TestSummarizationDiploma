# Sources

## Points 

# Script

#### Cтатистичні методи 
Найперші і найпростіші методи, які використовуються для реферування тексту - це статичні методи. Суть полягає в тому, щоб використовувати властивості тексту без того, щоб дивитись на взаємозвязки між словами чи реченнями. 
 
На що можна звертати увагу в тексті:
1. Використання найпопулярніших слів. Слова, яке найчастіше зустрічаються в тексі репрезентують основний концепт. Ці слова використовуються для оцінки речень, де пізніше ми вибираємо речення з найкращим балом.
2. Позиція в параграфі. За дослідженням Baxendale [4] ключову інформація в тексті надається або на початку або в кінці параграфу. Відповідно, що якщо брати перші речення з параграфу, то ти отримаєш якомога більше важливої інформації
3. Метод Едмундсона полягає в обєднанні інших статистичних методів. Едмундсон розглядав комбінацію декількох методів:
	- Популярність ключових слів (Key) -  описано в пункті 1 
	- Позиція речення в тексті (Location) - описано в пункті 2
	- Метод заголовка (Title) - де слова з заголовка тексту чи параграфа проганяються через Null dictionary (список слів, які не несуть ніякої емоційної забарвленості для тексту). Після чого ми формуємо список слів, що не потрапили в Null dictionary.
	- Метод ключових фраз (Cue) - беремо слова, які є в тексті і в залежності від того чи вони потрапляють в категорію (Bonus, Null, Stigma), де в залежності від категорії їм розраховують ваги. Далі для кожного речення обраховують вагу кожного речення і рангують.
	За методом Едмундсона нова оцінка речення буде складати з себе лінійну комбінацію рахунків з попередніх методів. Коефіцієнти при рахунках - це гіперпараметри, які обирає дослідник.
	Результати такого алгоритму показали, що найкраще показують себе Cue-Title-Location алгоритми (Див. Додаток Малюнок 1)


#### Методи класичного машинного навчання
Ідея цих методів полягає в тому, щоб використовувати задача класифікації для прогнозування "важливого" речення. 

##### Наївний баєсів класифікатор
Як уже було сказано раніше цей метод будується на задачі класифікації, де в нас є датасет для тренування, що складається з підходящих та не підходящих для реферування речень. З тексту також витягуються основні ознаки: частоти слів, кількість слів з великої букви, довжина рядка, позиція в параграфі, тощо [6]. 
Далі використовуючи формулу баєса ми для кожного речення визначаємо чи ймовірність потрапити в реферування використовуючи формулу нижче. 

$P(s \in S|F_1,F_2,...,F_k) = \frac{P(s \in S) \times \prod_{j=1}^{k} P(F_j| s \in S)}{\prod_{j=1}^k{P(F_j)}}$
 $P(s \in S)$ - ймовірність речення потрапити в реферування ( завжди константа)
 $P( F_j )$ - ймовірність ознаки  $F_j$
 $P(F_j|s \in S)$ - ймовірність ознаки $F_j$ за умови, що речення потрапило до реферування

Використання даного методу значно краще показує себе відносно інших методів класифікації зокрема в [7], де результат був показаний кращий за алгоритм дерева рішень C4.5, а також. 
В середньому такі алгоритми набирають 40-50 відсотків точності [7],[8] (див додаток малюнки 2,3)

Для прогнозування ключового речення можна також використовувати інші алгоритми для класифікацїі, зокрема SVM 

##### Ансамблі класичних методів 

##### Штучна нейронна мережа (ANN)
Не можна було б згадати використання нейронних мереж, зокрема найпопулярнійший варіант нейронної мережі [9]. 

Вхідними даними в даному випадку будуть речення в документі, де в кожному реченні буде наступний набір фіч:
1. Абзац після заголовка
2. Розташування абзацу в документі 
3. Розташування речення в абзаці 
4. Перше речення в абзаці 
5. Довжина речення 
6. Кількість тематичних слів у реченні 
7. Кількість слів заголовка в реченні

В статті для тренування використовували метод спряженого градієнта зі структурою нейронної мережі з шарами 7-6-1. В процесі тренування моделі через використання штрафної функції деякі нейрони були вилучені після чого деякі нейрони об'єднувались в кластери, де тепер активаційне значення цих нейронів отримуються з центроїда.  

В досліджуваному папері результати були доволі високими ( 96 відсотків) з приблизно 1500 досліджуваних речень ( 25 відсотків ключових речень).    

##### CNN та RNN 


#### TextRank

Один із перших методів навчання без учителя в сфері виділення ключових слів, а також реферування тексту, який був вперше представлений в далекому 2004 році, який створений на базі алгоритму PageRank [2]

Ідея алгоритму полягає в створенні графу залежностей між деякими структурами ( будь-то веб-сторінки, слова чи цілі речення). В нашому випадку відбувається наступне:
1. Кожне речення в тексті беремо як вершину графу
2. Кожне зєднання між нашими вершинами - це коефіцієнт, який репрезентує схожість двох речень. ( в оригінальній статті  це формула нижче ) ми також можемо використовувати і інші формули (косинусна схожість, cтрічкове ядро, найдовша підпослідовність)
$Similarity(S_i,S_j) =\frac{\omega_k|\omega_k \in S_i \cap S_j}{log(|S_i|)+log(|S_j|)}$
3. Після перших двох пунктів у нас формується граф з  вагами, на якому ми використовуємо PageRank алгоритм. 
	$Score(v_i) = (1 - d) + d \times \sum_{v_j \in In(v_i)} \frac{w_{ji}}{\sum_{v_k \in Out(v_j)} w_{jk}} \times Score(v_j)$
- Score(vi​) - оцінка вершини vi​.
- d - коефіцієнт згасання (зазвичай встановлюється на значення 0.85).
- In(vi​) - множина вершин, які вказують на вершину vi​.
- Out(vj​) - множина вершин, на які вказує вершина vj​.
- wji​ - вага ребра від вершини vj​ до vi​.
. 
4. Після декількох ітерацій алгоритму ми сортуємо за скором наші реченні і кращі перші використовуємо для створення короткого опису


### Додаток

![[image-11-x71-y83.png]]
Малюнок 1. Середні оцінки 
![[image-6-x309-y610.png]]
Малюнок 2. Результати [8]
![[image-7-x121-y304.png]]
Малюнок 3. Результати з [7]


### Refenences
[1] TextRank: Bringing Order into Text [[mihalceaTextRankBringingOrder2004]]
[2] The anatomy of a large-scale hypertextual Web search engine [[brinAnatomyofLargescalehypertextualWebSearchengine]]
[3] A survey on Automatic Text Summarization [[nazariSurveyAutomaticText2019]]
[4] Baxendale, P. B. (1958). Machine- Made Index for Technical Literature. An Experiment. IBM Journal of Research Development, vol. 4, no. 2, pp. 354-361. 
[5] Edmondson, H. P. (1969). New Methods in Automatic Extracting. Journal of the ACM, vol. 2, no. 16, pp. 264-285. [[edmundsonNewMethodsAutomatic1969]]
[6] A Trainable Document Summarizer, Julian Kupiec, Jan Pedersen and Francine Chen, 1995
[7] Automatic Text Summarization Using a Machine Learning Approach
Author: Joel Larocca Neto, Alex A. Freitas, Celso A. A. Kaestner [[netoAutomaticTextSummarization2002]]
[8] A Trainable Document Summarizer Using Bayesian Classifier Approach, Aditi Sharan , Hazra Imran, ManjuLata Joshi, 2008 [[sharanTrainableDocumentSummarizer2008]]
[9] Text Summarization Using Neural Networks, KHOSROW KAIKHAH [[kaikhahTextSummarizationUsing]]
[10]