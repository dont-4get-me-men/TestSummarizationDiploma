
# Script

#### Cтатистичні методи 
Найперші і найпростіші методи, які використовуються для реферування тексту - це статичні методи. Суть полягає в тому, щоб використовувати властивості тексту без того, щоб дивитись на взаємозвязки між словами чи реченнями. 
 
На що можна звертати увагу в тексті:
1. Використання найпопулярніших слів. Слова, яке найчастіше зустрічаються в тексі репрезентують основний концепт. Ці слова використовуються для оцінки речень, де пізніше ми вибираємо речення з найкращим балом.
2. Позиція в параграфі. За дослідженням Baxendale [4] ключову інформація в тексті надається або на початку або в кінці параграфу. Відповідно, що якщо брати перші речення з параграфу, то ти отримаєш якомога більше важливої інформації
3. Метод Едмундсона полягає в обєднанні інших статистичних методів. Едмундсон розглядав комбінацію декількох методів:
	- Популярність ключових слів (Key) -  описано в пункті 1 
	- Позиція речення в тексті (Location) - описано в пункті 2
	- Метод заголовка (Title) - де слова з заголовка тексту чи параграфа проганяються через Null dictionary (список слів, які не несуть ніякої емоційної забарвленості для тексту). Після чого ми формуємо список слів, що не потрапили в Null dictionary.
	- Метод ключових фраз (Cue) - беремо слова, які є в тексті і в залежності від того чи вони потрапляють в категорію (Bonus, Null, Stigma), де в залежності від категорії їм розраховують ваги. Далі для кожного речення обраховують вагу кожного речення і рангують.
	За методом Едмундсона нова оцінка речення буде складати з себе лінійну комбінацію рахунків з попередніх методів. Коефіцієнти при рахунках - це гіперпараметри, які обирає дослідник.
	Результати такого алгоритму показали, що найкраще показують себе Cue-Title-Location алгоритми (Див. Додаток Малюнок 1)


#### Методи класичного машинного навчання
Ідея цих методів полягає в тому, щоб використовувати задача класифікації для прогнозування "важливого" речення. Найбільша проблема в задачах такого типу (як в цілому подальших алгоритмів) це правильна репрезентація речення як вектора з чисел ( ембедінг). 
Серед рзіних варіацій ембедінгів є:
1. TF-IDF. Метод що базується на двох параметрах: частоти терміну (term frequency) і обернена частоту документа (inverse document frequency).
	 TF - репрезентує частота терміну серед всіх  термінів
	 IDF - репрезентує коефіцієнт рідкості слова серед документів. 
	 $\text{TF}(t,d) = \frac{\text{Number of times term } t \text{ appears in document } d}{\text{Total number of terms in document } d}$
	 $\text{IDF}(t,D) = \log\left(\frac{\text{Total number of documents in the corpus } N}{\text{Number of documents containing term } t}\right)$

2. BOW(Bag Of Words)  - мішочок слів. 
	 Нехай у нас є словник, який складається з всіх слів, які є в всіх документах.
	 Кожне речення буде репрезентуватись які вектор, де у навпроти колонки з кожним словом буде число входжень цього слова в реченні [12]

##### Наївний баєсів класифікатор
Як уже було сказано раніше цей метод будується на задачі класифікації, де в нас є датасет для тренування, що складається з підходящих та не підходящих для реферування речень. З тексту також витягуються основні ознаки: частоти слів, кількість слів з великої букви, довжина рядка, позиція в параграфі, тощо [6]. 
Далі використовуючи формулу баєса ми для кожного речення визначаємо чи ймовірність потрапити в реферування використовуючи формулу нижче. 

$P(s \in S|F_1,F_2,...,F_k) = \frac{P(s \in S) \times \prod_{j=1}^{k} P(F_j| s \in S)}{\prod_{j=1}^k{P(F_j)}}$
 $P(s \in S)$ - ймовірність речення потрапити в реферування ( завжди константа)
 $P( F_j )$ - ймовірність ознаки  $F_j$
 $P(F_j|s \in S)$ - ймовірність ознаки $F_j$ за умови, що речення потрапило до реферування

Використання даного методу значно краще показує себе відносно інших методів класифікації зокрема в [7], де результат був показаний кращий за алгоритм дерева рішень C4.5, а також. 
В середньому такі алгоритми набирають 40-50 відсотків точності [7],[8] (див додаток малюнки 2,3)

Для прогнозування ключового речення можна також використовувати інші алгоритми для класифікацїі, зокрема SVM 

##### Ансамблі класичних методів 

##### Штучна нейронна мережа (ANN)
Не можна було б згадати використання нейронних мереж, зокрема найпопулярнійший варіант нейронної мережі [9]. 

Вхідними даними в даному випадку будуть речення в документі, де в кожному реченні буде наступний набір фіч:
1. Абзац після заголовка
2. Розташування абзацу в документі 
3. Розташування речення в абзаці 
4. Перше речення в абзаці 
5. Довжина речення 
6. Кількість тематичних слів у реченні 
7. Кількість слів заголовка в реченні

В статті для тренування використовували метод спряженого градієнта зі структурою нейронної мережі з шарами 7-6-1. В процесі тренування моделі через використання штрафної функції деякі нейрони були вилучені після чого деякі нейрони об'єднувались в кластери, де тепер активаційне значення цих нейронів отримуються з центроїда.  

В досліджуваному папері результати були доволі високими ( 96 відсотків) з приблизно 1500 досліджуваних речень ( 25 відсотків ключових речень).    
#### Семантичні методи 
Не завжди фічі, які ми використовуємо для реферування тексту гарно репрезентують текст, адже не обовязково, щоб речення з найпопулярнішими словами несли багато змісту.

Через це семантичні методи намагаються інедтифікувати взаємовідносини слів між собою за допомогою граматичного аналізу, позначення частини мов, тощо. 
##### Метод лексичних ланцюгів

Доволі часто в тексті концепти, які були вказані раніше пізніше згадуються з використанням інших слів. Таким чином було запропоновано ці слова, які відсилаються один на одного комбінувати в ланцюги. 

Як модерувати ланцюг?
1. З самого початку ланцюг у нас пустий. 
2. Додаємо перше слово. 
3. Беручи нове слово ми перевіряємо чи воно зєднано з іншими словами в ланцюгах. Слова зєднані, якщо вони відповідають одному з декількох критерїв описаних в [10]. В основному це якщо слова знаходяться в одній чи зєднаних категоріях тезаурусу (в [11] використовувався WordNet).
4. У випадку, якщо ніякого звязку немає, то ми створюємо нову категорію 

Наступне, що нам треба зробити - це вибрати найкращі ланцюги зі всіх, які є. Зокрема в [11] вони використовуються оцінку виведену після ручного вибору найвагоміших ланцюгів. 



##### TextRank

Один із перших методів навчання без учителя в сфері виділення ключових слів, а також реферування тексту, який був вперше представлений в далекому 2004 році, який створений на базі алгоритму PageRank [2]

Ідея алгоритму полягає в створенні графу залежностей між деякими структурами ( будь-то веб-сторінки, слова чи цілі речення). В нашому випадку відбувається наступне:
1. Кожне речення в тексті беремо як вершину графу
2. Кожне зєднання між нашими вершинами - це коефіцієнт, який репрезентує схожість двох речень. ( в оригінальній статті  це формула нижче ) ми також можемо використовувати і інші формули (косинусна схожість, cтрічкове ядро, найдовша підпослідовність)
$Similarity(S_i,S_j) =\frac{\omega_k|\omega_k \in S_i \cap S_j}{log(|S_i|)+log(|S_j|)}$
3. Після перших двох пунктів у нас формується граф з  вагами, на якому ми використовуємо PageRank алгоритм. 
	$Score(v_i) = (1 - d) + d \times \sum_{v_j \in In(v_i)} \frac{w_{ji}}{\sum_{v_k \in Out(v_j)} w_{jk}} \times Score(v_j)$
- Score(vi​) - оцінка вершини vi​.
- d - коефіцієнт згасання (зазвичай встановлюється на значення 0.85).
- In(vi​) - множина вершин, які вказують на вершину vi​.
- Out(vj​) - множина вершин, на які вказує вершина vj​.
- wji​ - вага ребра від вершини vj​ до vi​.
. 
4. Після декількох ітерацій алгоритму ми сортуємо за оцінкою наші реченні і кращі перші використовуємо для створення короткого опису



##### Lex Rank


#### Методи з використанням нейронних мереж
##### Методи з використанням CNN
##### Методи з використанням RNN
### Додаток

![[image-11-x71-y83.png]]
Малюнок 1. Середні оцінки 
![[image-6-x309-y610.png]]
Малюнок 2. Результати [8]
![[image-7-x121-y304.png]]
Малюнок 3. Результати з [7]


### Refenences
[1] TextRank: Bringing Order into Text [[mihalceaTextRankBringingOrder2004]]
[2] The anatomy of a large-scale hypertextual Web search engine [[brinAnatomyofLargescalehypertextualWebSearchengine]]
[3] A survey on Automatic Text Summarization [[nazariSurveyAutomaticText2019]]
[4] Baxendale, P. B. (1958). Machine- Made Index for Technical Literature. An Experiment. IBM Journal of Research Development, vol. 4, no. 2, pp. 354-361. 
[5] Edmondson, H. P. (1969). New Methods in Automatic Extracting. Journal of the ACM, vol. 2, no. 16, pp. 264-285. [[edmundsonNewMethodsAutomatic1969]]
[6] A Trainable Document Summarizer, Julian Kupiec, Jan Pedersen and Francine Chen, 1995
[7] Automatic Text Summarization Using a Machine Learning Approach
Author: Joel Larocca Neto, Alex A. Freitas, Celso A. A. Kaestner [[netoAutomaticTextSummarization2002]]
[8] A Trainable Document Summarizer Using Bayesian Classifier Approach, Aditi Sharan , Hazra Imran, ManjuLata Joshi, 2008 [[sharanTrainableDocumentSummarizer2008]]
[9] Text Summarization Using Neural Networks, KHOSROW KAIKHAH [[kaikhahTextSummarizationUsing]]
[10]Lexical Chains as Representations of Context for the Detection and Correction of Malapropisms, Graeme Hirst, David St-onge, 1995
[11] Using Lexical Chains for Text Summarization, Regina Barzilay, Michael Elhadad, 1997
[12 ] Gentle inroduction to bag of Words https://machinelearningmastery.com/gentle-introduction-bag-words-model/