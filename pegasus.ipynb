{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T01:21:37.551217Z","iopub.status.busy":"2024-04-24T01:21:37.550028Z","iopub.status.idle":"2024-04-24T01:21:49.713419Z","shell.execute_reply":"2024-04-24T01:21:49.712207Z","shell.execute_reply.started":"2024-04-24T01:21:37.551173Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install rouge --quiet"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T01:21:49.716051Z","iopub.status.busy":"2024-04-24T01:21:49.715660Z","iopub.status.idle":"2024-04-24T01:22:00.521780Z","shell.execute_reply":"2024-04-24T01:22:00.520772Z","shell.execute_reply.started":"2024-04-24T01:21:49.716014Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"]}],"source":["import pandas as pd\n","import torch\n","from transformers import PegasusForConditionalGeneration, PegasusTokenizer, AdamW, get_linear_schedule_with_warmup\n","from torch.utils.data import DataLoader, Dataset\n","from rouge import Rouge\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T01:22:00.536906Z","iopub.status.busy":"2024-04-24T01:22:00.536158Z","iopub.status.idle":"2024-04-24T01:22:00.569935Z","shell.execute_reply":"2024-04-24T01:22:00.568939Z","shell.execute_reply.started":"2024-04-24T01:22:00.536872Z"},"trusted":true},"outputs":[],"source":["class SummarizationDataset(Dataset):\n","    def __init__(self, data, tokenizer, max_input_length=512, max_output_length=128):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.max_input_length = max_input_length\n","        self.max_output_length = max_output_length\n","    \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, index):\n","        article = self.data.iloc[index][\"article\"]\n","        summary = self.data.iloc[index][\"highlights\"]\n","        input_ids = self.tokenizer.encode(article, max_length=self.max_input_length, truncation=True, padding=\"max_length\")\n","        output_ids = self.tokenizer.encode(summary, max_length=self.max_output_length, truncation=True, padding=\"max_length\")\n","        return {\"input_ids\": input_ids, \"attention_mask\": [int(token_id != 0) for token_id in input_ids], \"decoder_input_ids\": output_ids[:-1], \"decoder_attention_mask\": [1] * (len(output_ids) - 1), \"labels\": output_ids[1:]}\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T01:22:00.571582Z","iopub.status.busy":"2024-04-24T01:22:00.571221Z","iopub.status.idle":"2024-04-24T01:22:29.774162Z","shell.execute_reply":"2024-04-24T01:22:29.773329Z","shell.execute_reply.started":"2024-04-24T01:22:00.571550Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv\")\n","test_df = pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv\")\n","val_df = pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T01:22:29.775590Z","iopub.status.busy":"2024-04-24T01:22:29.775291Z","iopub.status.idle":"2024-04-24T01:24:48.687449Z","shell.execute_reply":"2024-04-24T01:24:48.686375Z","shell.execute_reply.started":"2024-04-24T01:22:29.775564Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d08ea78b783481dba683e1fae146472","version_major":2,"version_minor":0},"text/plain":["Downloading spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9835ea3d16a459eae632ee99f192776","version_major":2,"version_minor":0},"text/plain":["Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5336c67d2d264a41af6183d74d077211","version_major":2,"version_minor":0},"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"820780505d7740acad579f0a8d00fea9","version_major":2,"version_minor":0},"text/plain":["Downloading config.json:   0%|          | 0.00/3.09k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1fc667c17177432e9cdc232276c392eb","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c071511f3eaf4f53a3f9c7e68b8832e2","version_major":2,"version_minor":0},"text/plain":["Downloading generation_config.json:   0%|          | 0.00/260 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-large\")\n","model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-large\")\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T01:24:48.689246Z","iopub.status.busy":"2024-04-24T01:24:48.688945Z","iopub.status.idle":"2024-04-24T01:24:48.693732Z","shell.execute_reply":"2024-04-24T01:24:48.692760Z","shell.execute_reply.started":"2024-04-24T01:24:48.689220Z"},"trusted":true},"outputs":[],"source":["train_dataset = SummarizationDataset(train_df, tokenizer)\n","val_dataset = SummarizationDataset(val_df, tokenizer)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T01:24:48.695931Z","iopub.status.busy":"2024-04-24T01:24:48.695578Z","iopub.status.idle":"2024-04-24T01:24:50.117434Z","shell.execute_reply":"2024-04-24T01:24:50.116518Z","shell.execute_reply.started":"2024-04-24T01:24:48.695899Z"},"trusted":true},"outputs":[],"source":["def collate_fn(batch):\n","    input_ids = [item[\"input_ids\"] for item in batch]\n","    attention_mask = [item[\"attention_mask\"] for item in batch]\n","    decoder_input_ids = [item[\"decoder_input_ids\"] for item in batch]\n","    decoder_attention_mask = [item[\"decoder_attention_mask\"] for item in batch]\n","    labels = [item[\"labels\"] for item in batch]\n","    max_input_length = max(len(ids) for ids in input_ids)\n","    max_output_length = max(len(ids) for ids in decoder_input_ids)\n","    input_ids = [ids + [0] * (max_input_length - len(ids)) for ids in input_ids]\n","    attention_mask = [mask + [0] * (max_input_length - len(mask)) for mask in attention_mask]\n","    decoder_input_ids = [ids + [0] * (max_output_length - len(ids)) for ids in decoder_input_ids]\n","    decoder_attention_mask = [mask + [0] * (max_output_length - len(mask)) for mask in decoder_attention_mask]\n","    labels = [ids + [-100] * (max_output_length - len(ids)) for ids in labels]\n","    return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T01:24:50.118883Z","iopub.status.busy":"2024-04-24T01:24:50.118533Z","iopub.status.idle":"2024-04-24T01:24:50.130810Z","shell.execute_reply":"2024-04-24T01:24:50.129996Z","shell.execute_reply.started":"2024-04-24T01:24:50.118858Z"},"trusted":true},"outputs":[],"source":["train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n","val_loader = DataLoader(val_dataset, batch_size=2,collate_fn=collate_fn)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T01:24:50.135430Z","iopub.status.busy":"2024-04-24T01:24:50.135164Z","iopub.status.idle":"2024-04-24T01:24:50.148759Z","shell.execute_reply":"2024-04-24T01:24:50.147759Z","shell.execute_reply.started":"2024-04-24T01:24:50.135408Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["optimizer = AdamW(model.parameters(), lr=5e-5)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=500, num_training_steps=10000)\n"]},{"cell_type":"markdown","metadata":{},"source":["x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-15T04:48:19.840477Z","iopub.status.busy":"2023-06-15T04:48:19.839916Z","iopub.status.idle":"2023-06-15T04:48:19.846601Z","shell.execute_reply":"2023-06-15T04:48:19.845721Z","shell.execute_reply.started":"2023-06-15T04:48:19.840445Z"},"trusted":true},"outputs":[],"source":["len(train_loader),len(val_loader)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T01:24:50.150211Z","iopub.status.busy":"2024-04-24T01:24:50.149934Z","iopub.status.idle":"2024-04-24T01:25:56.804495Z","shell.execute_reply":"2024-04-24T01:25:56.803562Z","shell.execute_reply.started":"2024-04-24T01:24:50.150187Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100it [00:50,  1.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step-100,Train Loss-10.285919189453125\n"]},{"name":"stderr","output_type":"stream","text":["100it [00:15,  6.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Step-100,Val Loss-8.724236488342285\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from tqdm import tqdm\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.train()\n","for epoch in range(10):\n","    train_loss = 0\n","    for step,batch in tqdm(enumerate(train_loader)):\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        loss = model(**batch).loss\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","        if step%100==0 and step>0:\n","            print(\"Step-{},Train Loss-{}\".format(step,loss.item()))\n","            break#intentionally breaking the training after 100 steps since it's going to take long to train,feel free to comment and train more\n","        train_loss += loss.item()\n","    train_loss /= len(train_loader)\n","    val_loss = 0\n","    model.eval()\n","    with torch.no_grad():\n","        for step,batch in tqdm(enumerate(val_loader)):\n","            batch = {k: v.to(device) for k, v in batch.items()}\n","            loss = model(**batch).loss\n","            val_loss += loss.item()\n","            if step%100==0 and step>0:\n","                print(\"Step-{},Val Loss-{}\".format(step,loss.item()))\n","                break #intentionally breaking the training after 100 steps since it's going to take long to validate,feel free to comment and validate more\n","        val_loss /= len(val_loader)\n","    model.train()\n","    break # when you train more then uncomment this, too !\n","    print(f\"Epoch {epoch+1} train loss: {train_loss:.4f} val loss: {val_loss:.4f}\")\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T01:25:56.806157Z","iopub.status.busy":"2024-04-24T01:25:56.805856Z","iopub.status.idle":"2024-04-24T01:25:59.760474Z","shell.execute_reply":"2024-04-24T01:25:59.759536Z","shell.execute_reply.started":"2024-04-24T01:25:56.806131Z"},"trusted":true},"outputs":[{"data":{"text/plain":["('fine_tuned_pegasus/tokenizer_config.json',\n"," 'fine_tuned_pegasus/special_tokens_map.json',\n"," 'fine_tuned_pegasus/spiece.model',\n"," 'fine_tuned_pegasus/added_tokens.json')"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["model.save_pretrained(\"fine_tuned_pegasus\")\n","tokenizer.save_pretrained(\"fine_tuned_pegasus\")\n"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["model = PegasusForConditionalGeneration.from_pretrained(\"fine_tuned_pegasus\")\n","tokenizer = PegasusTokenizer.from_pretrained(\"fine_tuned_pegasus\")\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T01:25:59.956411Z","iopub.status.busy":"2024-04-24T01:25:59.956107Z","iopub.status.idle":"2024-04-24T01:25:59.960671Z","shell.execute_reply":"2024-04-24T01:25:59.959772Z","shell.execute_reply.started":"2024-04-24T01:25:59.956385Z"},"trusted":true},"outputs":[],"source":["test_dataset = SummarizationDataset(test_df, tokenizer)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T01:25:59.962148Z","iopub.status.busy":"2024-04-24T01:25:59.961883Z","iopub.status.idle":"2024-04-24T01:25:59.972356Z","shell.execute_reply":"2024-04-24T01:25:59.971363Z","shell.execute_reply.started":"2024-04-24T01:25:59.962125Z"},"trusted":true},"outputs":[],"source":["test_loader = DataLoader(test_dataset, batch_size=1,collate_fn=collate_fn)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T01:25:59.973845Z","iopub.status.busy":"2024-04-24T01:25:59.973535Z","iopub.status.idle":"2024-04-24T01:25:59.984650Z","shell.execute_reply":"2024-04-24T01:25:59.983776Z","shell.execute_reply.started":"2024-04-24T01:25:59.973812Z"},"trusted":true},"outputs":[{"data":{"text/plain":["11490"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["len(test_loader)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T01:25:59.986316Z","iopub.status.busy":"2024-04-24T01:25:59.985970Z","iopub.status.idle":"2024-04-24T01:29:45.653511Z","shell.execute_reply":"2024-04-24T01:29:45.652422Z","shell.execute_reply.started":"2024-04-24T01:25:59.986284Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100it [03:45,  2.26s/it]\n"]}],"source":["model.to(device)\n","model.eval()\n","predictions = []\n","with torch.no_grad():\n","    for step, batch in tqdm(enumerate(test_loader)):\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        output_ids = model.generate(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"], max_length=128, decoder_start_token_id=tokenizer.pad_token_id)\n","        batch_predictions = [tokenizer.decode(ids, skip_special_tokens=True) for ids in output_ids]\n","        predictions.extend(batch_predictions)\n","        if step==100:\n","            break # breaking after generating 100 predictions.. since it's going to take long to predict on entire set\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T01:29:45.655528Z","iopub.status.busy":"2024-04-24T01:29:45.655090Z","iopub.status.idle":"2024-04-24T01:29:45.662342Z","shell.execute_reply":"2024-04-24T01:29:45.661318Z","shell.execute_reply.started":"2024-04-24T01:29:45.655490Z"},"trusted":true},"outputs":[{"data":{"text/plain":["101"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["len(predictions)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T01:29:45.664349Z","iopub.status.busy":"2024-04-24T01:29:45.663728Z","iopub.status.idle":"2024-04-24T01:29:45.700436Z","shell.execute_reply":"2024-04-24T01:29:45.699492Z","shell.execute_reply.started":"2024-04-24T01:29:45.664311Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["101\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_32/959527322.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  test_df[\"predictions\"] = predictions\n"]}],"source":["# Save the predictions to a CSV file\n","test_df = test_df[:101]# for 100 predicitons only\n","print(len(test_df))\n","test_df[\"predictions\"] = predictions\n","test_df.to_csv(\"test_predictions.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-15T04:53:38.850433Z","iopub.status.busy":"2023-06-15T04:53:38.849789Z","iopub.status.idle":"2023-06-15T04:53:38.869229Z","shell.execute_reply":"2023-06-15T04:53:38.868245Z","shell.execute_reply.started":"2023-06-15T04:53:38.850392Z"},"trusted":true},"outputs":[],"source":["test_df"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T01:29:46.712205Z","iopub.status.busy":"2024-04-24T01:29:46.711911Z","iopub.status.idle":"2024-04-24T01:29:47.191599Z","shell.execute_reply":"2024-04-24T01:29:47.190505Z","shell.execute_reply.started":"2024-04-24T01:29:46.712180Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ROUGE-1: 0.3209\n","ROUGE-2: 0.1259\n","ROUGE-L: 0.2935\n"]}],"source":["# Calculate the ROUGE scores between the predicted summaries and the actual summaries\n","rouge = Rouge()\n","scores = rouge.get_scores(predictions, test_df[\"highlights\"].tolist(), avg=True)\n","\n","# Print the ROUGE scores\n","print(f\"ROUGE-1: {scores['rouge-1']['f']:.4f}\")\n","print(f\"ROUGE-2: {scores['rouge-2']['f']:.4f}\")\n","print(f\"ROUGE-L: {scores['rouge-l']['f']:.4f}\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1654566,"sourceId":2734496,"sourceType":"datasetVersion"},{"datasetId":3379062,"sourceId":6067666,"sourceType":"datasetVersion"}],"dockerImageVersionId":30498,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
